### ZKML Q&A

**Q: How much performance loss using ZoKrates vs. Circom?**
**A:** ZoKrates generally slower; Circom optimized for R1CS/SNARKs (e.g., 15s RSA vs. 1min zk-email in Circom). ZoKrates DSL higher-level but less efficient for large circuits; use Circom for speed.

**Q: Comparison between GKR protocol and Circom?**
**A:** GKR: Interactive proof for circuit evaluation (linear prover, sublinear verifier). Circom: DSL for ZK circuits (compiles to R1CS for SNARKs/STARKs). GKR for aggregation; Circom for circuit building.

**Q: How important is legible circuit code comparable to non-circuit ML code?**
**A:** Important for auditing/verification; ensures correctness without ZK abstraction hiding bugs.

**Q: Uses of ZK on evasion attacks? E.g., white-hat hacker for ML bug bounty?**
**A:** ZK proves model robustness without revealing attack vectors; white-hat bounties possible via verifiable evasion tests.

**Q: Good idea for OpenAI to use ZKML on inference to prove correct model use, not lower one?**
**A:** Yes; proves exact model execution without parameter reveal, ensuring integrity.

**Q: Viable/useful to provide model as private input in ZKML?**
**A:** Viable; hides proprietary models while proving inference correctness.

**Q: How is ZKML use in healthcare different from federated learning?**
**A:** ZKML proves computation privacy (no data sharing); FL aggregates models without raw data. ZKML for verifiable inference; FL for collaborative training.

**Q: Why did Web3 fail in supply chain? Privacy reasons?**
**A:** Privacy exposure via transparency; complex integration, regulatory hurdles, scalability issues beyond privacy.

**Q: What is the signature for in the attested microphone map?**
**A:** Hardware ECDSA signature links audio to device; ZK-SNARKs extend trust for edits.

**Q: With LLM parameters expanding, ZKML verifies computation but not biasâ€”won't catch up or offer value?**
**A:** ZKML verifies execution; bias detection needs separate tools. Value in privacy/integrity despite growth.

**Q: Know TensorFlow ZKML applications? Mystique in Rosetta framework? Used in projects?**
**A:** Yes; Mystique enables ZK conversions for ML in Rosetta (TensorFlow privacy framework). Used for secure inference (e.g., ResNet).

**Q: EZKL demo produces 130 MB PK for 1-parameter model! Size for 8M model?**
**A:** Scales with complexity; 8M params could reach GBs (e.g., 5x faster proving but large PKs). Optimize via quantization.

### Class 4 QA

**Q: Comment on privy.io embedded wallets offering this approach?**
**A:** Privy.io embedded wallets streamline user onboarding with ZK-based authentication; great for UX and security.

**Q: What does quantization mean? Like rounding up or down?**
**A:** Quantization maps floating-point values to fixed-point or integers (e.g., rounding to discrete levels) to reduce precision for efficiency in ZK circuits.

**Q: What is a lookup argument? Isnâ€™t keeping all possible input/output pairs costly?**
**A:** Lookup arguments verify values in precomputed tables efficiently (e.g., Plookup). Costly for large tables, but optimized via commitments or logarithmic checks.

**Q: Does the output column contain gates and final outputs?**
**A:** Output column in arithmetic circuits typically holds final computation results, not gates. Gates define operations; outputs are results.

**Q: Do neurons use floating-point? System for FP in finite fields?**
**A:** Yes, neurons often use floating-point. In ZK, FP approximated via fixed-point or scaled integers to fit finite fields, requiring careful precision management.

**Q: Is Groth16 still frequently used in industry? Will it continue?**
**A:** Yes, widely used for efficiency (small proofs, fast verification). Likely to continue where trusted setup is acceptable.

**Q: ZK with floats? Impossible?**
**A:** Not impossible; floats approximated as fixed-point or integers in finite fields. Precision loss manageable with scaling.

**Q: What is meant by a weightless approach?**
**A:** Weightless approach in ZKML skips model weights as inputs (e.g., proving inference without weights), reducing circuit complexity.

**Q: Are costly range proofs for wide ranges a challenge for activation functions with thresholds?**
**A:** Yes, wide ranges increase range proof costs. Activation functions (e.g., ReLU) need optimized circuits or lookup tables to manage thresholds efficiently.
